server.port: 7003
server.error.include-message: always

# With the database in place, we now need to set up the configuration for the core microservices so they
# know how to connect to their databases. This is set up in each core microservice’s configuration file,
# application.yml
# By default, Hibernate will be used by Spring Data JPA as JPA’s EntityManager.
# Strongly recommend to set this property to "none" in a production environment!
# The spring.jpa.hibernate.ddl-auto property is used to tell Spring Data JPA to create new or update existing SQL tables during startup.
spring.jpa.hibernate.ddl-auto: update

spring.datasource:
  url: jdbc:mysql://localhost/review-db
  username: user
  password: pwd

# This means that the Spring Boot application will wait for up to 60 seconds during startup to establish a database connection.
spring.datasource.hikari.initializationFailTimeout: 60000

# this specifies which spring function bean we want to run, message processor bean that I have defined. That means
# whatever message come from rabbitMq or Kafka, spring cloud stream will invoke this function.
spring.cloud.function.definition: messageProcessor

# Means my message processor has to consume message from the recommendation topic, for this I have defined
# a binding. Mere messageProcessor jo ke -in- input type ka hai usko destination:recommendations queue/topic ke
# sath bind kardo. Ye hum springCloud stream ko bata rahy hain.
spring.cloud.stream:
  defaultBinder: rabbit #binder means messaging system, by default we will use rabbitMQ
  default.contentType: application/json
  bindings.messageProcessor-in-0: # Binding = connection between your app function and the message destination (topic/queue).
    destination: reviews  # Name of the topic/queue where message will be consumed.
    group: reviewsGroup

spring.cloud.stream.bindings.messageProcessor-in-0.consumer:
  maxAttempts: 3
  backOffInitialInterval: 500
  backOffMaxInterval: 1000
  backOffMultiplier: 2.0

spring.cloud.stream.rabbit.bindings.messageProcessor-in-0.consumer:
  autoBindDlq: true
  republishToDlq: true

spring.cloud.stream.kafka.bindings.messageProcessor-in-0.consumer:
  enableDlq: true

spring.cloud.stream.kafka.binder:
  brokers: 127.0.0.1
  defaultBrokerPort: 9092

spring.rabbitmq:
  host: 127.0.0.1
  port: 5672
  username: guest
  password: guest

logging:
  level:
    root: INFO
    com.microservices: DEBUG
    org.hibernate.SQL: DEBUG
    org.hibernate.type.descriptor.sql.BasicBinder: TRACE




# Values in a profile override values from the default profile. By using YAML files, multiple Spring profiles
#  can be placed in the same file, separated by ---
---

# To handle the different configurations that are required when running locally without Docker and
# when running the microservices as Docker containers, we will use Spring profiles. Now, we will create a new
# Spring profile named docker to be used when we run our microservices as containers in Docker.


spring.config.activate.on-profile: docker

server.port: 8080

spring.datasource:
  url: jdbc:mysql://mysql/review-db

spring.rabbitmq.host: rabbitmq
spring.cloud.stream.kafka.binder.brokers: kafka


---
spring.config.activate.on-profile: streaming_partitioned

spring.cloud.stream.bindings.messageProcessor-in-0.consumer:
  partitioned: true
  instanceCount: 2

---
spring.config.activate.on-profile: streaming_instance_0
spring.cloud.stream.bindings.messageProcessor-in-0.consumer.instanceIndex: 0

---

spring.config.activate.on-profile: streaming_instance_1
spring.cloud.stream.bindings.messageProcessor-in-0.consumer.instanceIndex: 1


---
spring.config.activate.on-profile: kafka
management.health.rabbit.enabled: false
spring.cloud.stream.defaultBinder: kafka
spring.kafka.bootstrap-servers: kafka:9092
spring.cloud.stream.kafka.binder.replication-factor: 1

